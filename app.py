from flask import Flask, render_template, request, redirect, url_for, session, send_file, flash, jsonify
import os

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # python-dotenvãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    pass

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šï¼šé–‹ç™ºç’°å¢ƒã§ã®HTTPä½¿ç”¨ã‚’ç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡
# æœ¬ç•ªç’°å¢ƒã§ã¯ '0' ã¾ãŸã¯æœªè¨­å®šã«ã—ã¦HTTPSã‚’å¼·åˆ¶ã™ã‚‹ã“ã¨
if os.environ.get('OAUTHLIB_INSECURE_TRANSPORT', '0') == '1':
    os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1' 
import datetime
import csv
import re
import tempfile
import sqlite3
import hashlib
from typing import List, Dict, Any, Optional, Tuple

# Google API libraries
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import Flow
from googleapiclient.discovery import build
import googlemaps

app = Flask(__name__)
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ï¼šç’°å¢ƒå¤‰æ•°ã‹ã‚‰ç§˜å¯†éµã‚’å–å¾—
app.secret_key = os.environ.get('SECRET_KEY', 'your_secret_key_change_this_in_production')

# DoSæ”»æ’ƒå¯¾ç­–ï¼šã‚¤ãƒ™ãƒ³ãƒˆå–å¾—æ•°ã®åˆ¶é™
MAX_EVENTS = 1000
MAX_DAYS_RANGE = 365  # æœ€å¤§1å¹´é–“ã®ç¯„å›²åˆ¶é™

# ãƒªãƒãƒ¼ã‚¹ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è¨­å®š
CACHE_DB_FILE = os.environ.get('CACHE_DB_PATH', 'geocoding_cache.db')
CACHE_PRECISION = 4  # åº§æ¨™ã®ç²¾åº¦ï¼ˆå°æ•°ç‚¹ä»¥ä¸‹ã®æ¡æ•°ï¼‰

# OAuthè¨­å®š
CLIENT_SECRETS_FILE = 'credentials.json'
SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']
API_SERVICE_NAME = 'calendar'
API_VERSION = 'v3'

@app.route('/')
def index():
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    # èªè¨¼çŠ¶æ…‹ã‚’ç¢ºèª
    if 'credentials' in session:
        return render_template('index.html', authenticated=True)
    else:
        return render_template('index.html', authenticated=False)

@app.route('/authorize')
def authorize():
    """Googleèªè¨¼ã‚’é–‹å§‹"""
    # èªè¨¼ãƒ•ãƒ­ãƒ¼ã‚’ä½œæˆ
    flow = Flow.from_client_secrets_file(
        CLIENT_SECRETS_FILE, 
        scopes=SCOPES,
        redirect_uri=url_for('oauth2callback', _external=True)
    )
    
    # èªè¨¼URLã‚’å–å¾—
    authorization_url, state = flow.authorization_url(
        access_type='offline',
        include_granted_scopes='true'
    )
    
    # çŠ¶æ…‹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
    session['state'] = state
    
    # èªè¨¼URLã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
    return redirect(authorization_url)

@app.route('/oauth2callback')
def oauth2callback():
    """Googleèªè¨¼ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    state = session['state']
    
    # èªè¨¼ãƒ•ãƒ­ãƒ¼ã‚’ä½œæˆ
    flow = Flow.from_client_secrets_file(
        CLIENT_SECRETS_FILE, 
        scopes=SCOPES,
        state=state,
        redirect_uri=url_for('oauth2callback', _external=True)
    )
    
    # èªè¨¼ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³ã¨äº¤æ›
    authorization_response = request.url
    flow.fetch_token(authorization_response=authorization_response)
    
    # èªè¨¼æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
    credentials = flow.credentials
    session['credentials'] = {
        'token': credentials.token,
        'refresh_token': credentials.refresh_token,
        'token_uri': credentials.token_uri,
        'client_id': credentials.client_id,
        'client_secret': credentials.client_secret,
        'scopes': credentials.scopes
    }
    
    return redirect(url_for('index'))

@app.route('/logout')
def logout():
    """ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"""
    if 'credentials' in session:
        del session['credentials']
    return redirect(url_for('index'))

@app.route('/generate_report', methods=['POST'])
def generate_report():
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¨ãƒ–ãƒ©ã‚¦ã‚¶è¡¨ç¤º"""
    if 'credentials' not in session:
        return redirect(url_for('authorize'))
    
    # ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
    start_date = request.form.get('start_date')
    end_date = request.form.get('end_date')
    calendar_id = request.form.get('calendar_id', '').strip()
    maps_api_key = request.form.get('maps_api_key', '').strip()
    
    # å…¥åŠ›å€¤æ¤œè¨¼
    if not maps_api_key:
        return render_template('index.html', 
                              authenticated=True, 
                              error="Google Maps APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼šAPIã‚­ãƒ¼ã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
    if len(maps_api_key) < 10 or len(maps_api_key) > 100:
        return render_template('index.html', 
                              authenticated=True, 
                              error="Google Maps APIã‚­ãƒ¼ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
    
    # æ—¥ä»˜ç¯„å›²ã®è¨­å®šï¼ˆUTCã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’è¿½åŠ ï¼‰
    if start_date and end_date:
        try:
            start_date = datetime.datetime.strptime(start_date, '%Y-%m-%d')
            end_date = datetime.datetime.strptime(end_date, '%Y-%m-%d')
            end_date = end_date.replace(hour=23, minute=59, second=59)
            
            # DoSæ”»æ’ƒå¯¾ç­–ï¼šæ—¥ä»˜ç¯„å›²ã‚’ãƒã‚§ãƒƒã‚¯
            date_range = (end_date - start_date).days
            if date_range < 0:
                return render_template('index.html', 
                                      authenticated=True, 
                                      error="é–‹å§‹æ—¥ã¯çµ‚äº†æ—¥ã‚ˆã‚Šå‰ã®æ—¥ä»˜ã«ã—ã¦ãã ã•ã„")
            if date_range > MAX_DAYS_RANGE:
                return render_template('index.html', 
                                      authenticated=True, 
                                      error=f"æ—¥ä»˜ç¯„å›²ã¯{MAX_DAYS_RANGE}æ—¥ä»¥å†…ã«ã—ã¦ãã ã•ã„")
            
            # UTCã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’è¿½åŠ 
            start_date = start_date.replace(tzinfo=datetime.timezone.utc)
            end_date = end_date.replace(tzinfo=datetime.timezone.utc)
        except ValueError:
            return render_template('index.html', 
                                  authenticated=True, 
                                  error="æ—¥ä»˜ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å½“æœˆ
        start_date, end_date = get_first_and_last_day_of_month()
        end_date = end_date.replace(hour=23, minute=59, second=59)
        # UTCã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’è¿½åŠ 
        start_date = start_date.replace(tzinfo=datetime.timezone.utc)
        end_date = end_date.replace(tzinfo=datetime.timezone.utc)
    
    # Google ã‚µãƒ¼ãƒ“ã‚¹ã®èªè¨¼
    credentials = Credentials(**session['credentials'])
    calendar_service = build(API_SERVICE_NAME, API_VERSION, credentials=credentials)
    gmaps_client = googlemaps.Client(key=maps_api_key)
    
    # é‹è»¢ãƒ­ã‚°ã®å–å¾—
    driving_logs = get_driving_logs(start_date, end_date, calendar_service, gmaps_client, calendar_id or 'primary')
    
    # æ—¥ä»˜ã®è¡¨ç¤ºå½¢å¼ã‚’æ•´ãˆã‚‹
    for log in driving_logs:
        if log['start_time']:
            start_dt = datetime.datetime.fromisoformat(log['start_time'].replace('Z', '+00:00'))
            log['start_time_formatted'] = start_dt.strftime('%Y-%m-%d %H:%M')
        else:
            log['start_time_formatted'] = "ä¸æ˜"
            
        if log['end_time']:
            end_dt = datetime.datetime.fromisoformat(log['end_time'].replace('Z', '+00:00'))
            log['end_time_formatted'] = end_dt.strftime('%Y-%m-%d %H:%M')
        else:
            log['end_time_formatted'] = "ä¸æ˜"
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«CSVã‚’å‡ºåŠ›ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰
    fd, path = tempfile.mkstemp(suffix='.csv')
    os.close(fd)  # fdã‚’é–‰ã˜ã‚‹
    export_to_csv(driving_logs, path)  # ãƒ‘ã‚¹ã‚’ç›´æ¥æ¸¡ã™
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
    session['temp_csv_path'] = path
    session['report_filename'] = f'driving_report_{start_date.strftime("%Y%m%d")}_{end_date.strftime("%Y%m%d")}.csv'
    
    return render_template('report.html', 
                          logs=driving_logs, 
                          start_date=start_date.strftime('%Y-%m-%d'),
                          end_date=end_date.strftime('%Y-%m-%d'),
                          calendar_id=calendar_id or 'primary')

@app.route('/download_csv')
def download_csv():
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆShift_JISå½¢å¼ï¼‰"""
    if 'temp_csv_path' not in session or 'report_filename' not in session:
        return redirect(url_for('index'))
    
    path = session['temp_csv_path']
    filename = session['report_filename']
    
    # Excelã§é–‹ãã‚„ã™ãã™ã‚‹ãŸã‚ã®ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
    response = send_file(
        path,
        as_attachment=True,
        download_name=filename,
        mimetype='text/csv;charset=shift_jis'
    )
    
    # Content-Typeãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
    response.headers['Content-Type'] = 'text/csv;charset=shift_jis'
    
    return response

@app.route('/cache')
def cache_management():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    if 'credentials' not in session:
        return redirect(url_for('authorize'))
    
    try:
        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—
        cache_entries, total_count = get_cache_entries_paginated(page, per_page)
        total_pages = (total_count + per_page - 1) // per_page
        
        print(f"Retrieved {len(cache_entries)} cache entries (page {page}/{total_pages})")
        return render_template('cache.html', 
                               cache_entries=cache_entries,
                               current_page=page,
                               total_pages=total_pages,
                               total_count=total_count,
                               per_page=per_page)
    except Exception as e:
        print(f"Error in cache_management: {e}")
        return f"Error: {e}", 500

@app.route('/cache/delete/<cache_id>', methods=['POST'])
def delete_cache_entry(cache_id):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤"""
    if 'credentials' not in session:
        return jsonify({'error': 'Not authenticated'}), 401
    
    success = delete_cache_by_hash(cache_id)
    if success:
        flash('ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤ã—ã¾ã—ãŸ', 'success')
        return jsonify({'success': True})
    else:
        return jsonify({'error': 'Failed to delete cache entry'}), 500

@app.route('/cache/update/<cache_id>', methods=['POST'])
def update_cache_entry(cache_id):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã®ä½æ‰€ã‚’æ›´æ–°"""
    if 'credentials' not in session:
        return jsonify({'error': 'Not authenticated'}), 401
    
    new_address = (request.json or {}).get('address', '').strip()
    if not new_address:
        return jsonify({'error': 'Address cannot be empty'}), 400
    
    success = update_cache_address(cache_id, new_address)
    if success:
        flash('ä½æ‰€ã‚’æ›´æ–°ã—ã¾ã—ãŸ', 'success')
        return jsonify({'success': True})
    else:
        return jsonify({'error': 'Failed to update cache entry'}), 500

@app.route('/cache/clear', methods=['POST'])
def clear_all_cache():
    """å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤"""
    if 'credentials' not in session:
        return jsonify({'error': 'Not authenticated'}), 401
    
    success = clear_cache_database()
    if success:
        flash('å…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤ã—ã¾ã—ãŸ', 'success')
        return jsonify({'success': True})
    else:
        return jsonify({'error': 'Failed to clear cache'}), 500

def get_first_and_last_day_of_month():
    """Get the first and last day of the current month with UTC timezone."""
    today = datetime.datetime.now(datetime.timezone.utc)
    first_day = datetime.datetime(today.year, today.month, 1, tzinfo=datetime.timezone.utc)
    if today.month == 12:
        last_day = datetime.datetime(today.year + 1, 1, 1, tzinfo=datetime.timezone.utc) - datetime.timedelta(days=1)
    else:
        last_day = datetime.datetime(today.year, today.month + 1, 1, tzinfo=datetime.timezone.utc) - datetime.timedelta(days=1)
    return first_day, last_day

def init_cache_db():
    """Initialize the geocoding cache database."""
    conn = sqlite3.connect(CACHE_DB_FILE)
    cursor = conn.cursor()
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS geocoding_cache (
            coordinate_hash TEXT PRIMARY KEY,
            latitude REAL NOT NULL,
            longitude REAL NOT NULL,
            address TEXT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šï¼‰
    cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_coordinates 
        ON geocoding_cache(latitude, longitude)
    ''')
    
    conn.commit()
    conn.close()

def get_coordinate_hash(lat: float, lng: float) -> str:
    """Generate a hash for coordinates with specified precision."""
    # æŒ‡å®šã•ã‚ŒãŸç²¾åº¦ã«ä¸¸ã‚ã‚‹
    rounded_lat = round(lat, CACHE_PRECISION)
    rounded_lng = round(lng, CACHE_PRECISION)
    
    # ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ
    coord_string = f"{rounded_lat},{rounded_lng}"
    return hashlib.md5(coord_string.encode()).hexdigest()

def get_cached_address(lat: float, lng: float) -> Optional[str]:
    """Get cached address for coordinates."""
    try:
        conn = sqlite3.connect(CACHE_DB_FILE)
        cursor = conn.cursor()
        
        coord_hash = get_coordinate_hash(lat, lng)
        cursor.execute(
            'SELECT address FROM geocoding_cache WHERE coordinate_hash = ?',
            (coord_hash,)
        )
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            print(f"Cache hit for coordinates ({lat}, {lng})")
            return result[0]
        
        return None
    except Exception as e:
        print(f"Error accessing cache: {e}")
        return None

def cache_address(lat: float, lng: float, address: str):
    """Cache address for coordinates."""
    try:
        conn = sqlite3.connect(CACHE_DB_FILE)
        cursor = conn.cursor()
        
        coord_hash = get_coordinate_hash(lat, lng)
        rounded_lat = round(lat, CACHE_PRECISION)
        rounded_lng = round(lng, CACHE_PRECISION)
        
        # INSERT OR REPLACE ã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
        cursor.execute('''
            INSERT OR REPLACE INTO geocoding_cache 
            (coordinate_hash, latitude, longitude, address, created_at)
            VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)
        ''', (coord_hash, rounded_lat, rounded_lng, address))
        
        conn.commit()
        conn.close()
        
        print(f"Cached address for coordinates ({lat}, {lng}): {address}")
    except Exception as e:
        print(f"Error caching address: {e}")

def get_all_cache_entries() -> List[Dict[str, Any]]:
    """Get all cache entries for management interface."""
    try:
        conn = sqlite3.connect(CACHE_DB_FILE)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT coordinate_hash, latitude, longitude, address, created_at
            FROM geocoding_cache
            ORDER BY created_at DESC
        ''')
        
        entries = []
        for row in cursor.fetchall():
            entries.append({
                'hash': row[0],
                'latitude': row[1],
                'longitude': row[2],
                'address': row[3],
                'created_at': row[4]
            })
        
        conn.close()
        return entries
    except Exception as e:
        print(f"Error getting cache entries: {e}")
        return []

def get_cache_entries_paginated(page: int, per_page: int) -> Tuple[List[Dict[str, Any]], int]:
    """Get paginated cache entries for management interface."""
    try:
        conn = sqlite3.connect(CACHE_DB_FILE)
        cursor = conn.cursor()
        
        # ç·æ•°ã‚’å–å¾—
        cursor.execute('SELECT COUNT(*) FROM geocoding_cache')
        total_count = cursor.fetchone()[0]
        
        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        offset = (page - 1) * per_page
        cursor.execute('''
            SELECT coordinate_hash, latitude, longitude, address, created_at
            FROM geocoding_cache
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        ''', (per_page, offset))
        
        entries = []
        for row in cursor.fetchall():
            entries.append({
                'hash': row[0],
                'latitude': row[1],
                'longitude': row[2],
                'address': row[3],
                'created_at': row[4]
            })
        
        conn.close()
        return entries, total_count
    except Exception as e:
        print(f"Error getting paginated cache entries: {e}")
        return [], 0

def delete_cache_by_hash(coordinate_hash: str) -> bool:
    """Delete a cache entry by its hash."""
    try:
        conn = sqlite3.connect(CACHE_DB_FILE)
        cursor = conn.cursor()
        
        cursor.execute(
            'DELETE FROM geocoding_cache WHERE coordinate_hash = ?',
            (coordinate_hash,)
        )
        
        conn.commit()
        affected_rows = cursor.rowcount
        conn.close()
        
        return affected_rows > 0
    except Exception as e:
        print(f"Error deleting cache entry: {e}")
        return False

def update_cache_address(coordinate_hash: str, new_address: str) -> bool:
    """Update the address for a cache entry."""
    try:
        conn = sqlite3.connect(CACHE_DB_FILE)
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE geocoding_cache 
            SET address = ?, created_at = CURRENT_TIMESTAMP
            WHERE coordinate_hash = ?
        ''', (new_address, coordinate_hash))
        
        conn.commit()
        affected_rows = cursor.rowcount
        conn.close()
        
        return affected_rows > 0
    except Exception as e:
        print(f"Error updating cache entry: {e}")
        return False

def clear_cache_database() -> bool:
    """Clear all cache entries."""
    try:
        conn = sqlite3.connect(CACHE_DB_FILE)
        cursor = conn.cursor()
        
        cursor.execute('DELETE FROM geocoding_cache')
        
        conn.commit()
        conn.close()
        
        return True
    except Exception as e:
        print(f"Error clearing cache: {e}")
        return False

def parse_event_title(title: str) -> Tuple[Optional[float], Optional[float]]:
    """Parse distance and fuel efficiency from event title."""
    # ä¿®æ­£ã—ãŸæ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ - æ•´æ•°éƒ¨åˆ†ãŒ0ã®å ´åˆã‚‚å¯¾å¿œã—ã€km/lã‚’å«ã‚€
    match = re.search(r'è·é›¢(\d*\.\d+|\d+)km\s*\((\d*\.\d+|\d+)km/l\)', title)
    if match:
        return float(match.group(1)), float(match.group(2))
    return None, None

def get_address_from_location(gmaps_client: Any, location: str) -> str:
    """Convert coordinates to address using Google Maps reverse geocoding with caching."""
    if not location:
        return "ä¸æ˜"  # Unknown
    
    try:
        # Extract coordinates from location string
        coord_match = re.search(r'(-?\d+\.\d+),\s*(-?\d+\.\d+)', location)
        if not coord_match:
            return "ä¸æ˜"  # Unknown
        
        lat, lng = float(coord_match.group(1)), float(coord_match.group(2))
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ä½æ‰€ã‚’å–å¾—ã‚’è©¦è¡Œ
        cached_address = get_cached_address(lat, lng)
        if cached_address:
            return cached_address
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã„å ´åˆã¯Google Maps APIã‚’ä½¿ç”¨
        print(f"Cache miss for coordinates ({lat}, {lng}) - calling Google Maps API")
        reverse_geocode_result = gmaps_client.reverse_geocode(
            (lat, lng),
            language="ja"
        )
        
        if reverse_geocode_result:
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ä½æ‰€ã‚’å–å¾—
            formatted_address = reverse_geocode_result[0]['formatted_address']
            
            # ã€Œæ—¥æœ¬ã€ã€’XXX-XXXX ã€ã®éƒ¨åˆ†ã‚’å‰Šé™¤
            formatted_address = re.sub(r'^æ—¥æœ¬ã€\s*', '', formatted_address)
            formatted_address = re.sub(r'ã€’\d{3}-\d{4}\s*', '', formatted_address)
            
            # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            cache_address(lat, lng, formatted_address)
            
            return formatted_address
            
        return "ä¸æ˜"  # Unknown
    except Exception as e:
        print(f"Error in reverse geocoding: {e}")
        return "ä¸æ˜"  # Unknown

def get_driving_logs(start_date: datetime.datetime, end_date: datetime.datetime, 
                     calendar_service: Any, gmaps_client: Any, calendar_id: str = 'primary') -> List[Dict[str, Any]]:
    """Retrieve driving logs from Google Calendar."""
    logs = []
    
    # æŒ‡å®šæœŸé–“ã‚ˆã‚Šå‰ã®æœ€å¾Œã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—ã™ã‚‹ãŸã‚ã€ã‚ˆã‚Šåºƒã„ç¯„å›²ã§ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—
    # 7æ—¥å‰ã‹ã‚‰å–å¾—ã—ã¦ã€æœŸé–“å¤–ã®ç›´å‰ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ã‚‹
    extended_start_date = start_date - datetime.timedelta(days=7)
    
    # æ—¥ä»˜ã‚’æ­£ã—ã„UTCãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›ï¼ˆã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ã‚’é™¤ã„ã¦Zã‚’è¿½åŠ ï¼‰
    extended_start_str = extended_start_date.strftime('%Y-%m-%dT%H:%M:%S') + 'Z'
    end_date_str = end_date.strftime('%Y-%m-%dT%H:%M:%S') + 'Z'
    
    try:
        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼IDã‚’æŒ‡å®šã—ã¦ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—ï¼ˆæ‹¡å¼µæœŸé–“ï¼‰
        # DoSæ”»æ’ƒå¯¾ç­–ï¼šå–å¾—ã‚¤ãƒ™ãƒ³ãƒˆæ•°ã‚’åˆ¶é™
        events_result = calendar_service.events().list(
            calendarId=calendar_id,
            timeMin=extended_start_str,
            timeMax=end_date_str,
            singleEvents=True,
            orderBy='startTime',
            maxResults=MAX_EVENTS
        ).execute()
    except Exception as e:
        print(f"Error fetching calendar events: {e}")
        return []
    
    events = events_result.get('items', [])
    
    # æŒ‡å®šæœŸé–“å¤–ã®ç›´å‰ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ã‚‹
    previous_event = None
    for event in events:
        event_start = event['start'].get('dateTime')
        if event_start and 'è·é›¢' in event.get('summary', ''):
            event_start_dt = datetime.datetime.fromisoformat(event_start.replace('Z', '+00:00'))
            if event_start_dt < start_date:
                previous_event = event  # æœŸé–“å‰ã®æœ€å¾Œã®é‹è»¢ã‚¤ãƒ™ãƒ³ãƒˆ
            else:
                break  # æŒ‡å®šæœŸé–“ã«å…¥ã£ãŸã®ã§çµ‚äº†
    
    # æŒ‡å®šæœŸé–“å†…ã®ã‚¤ãƒ™ãƒ³ãƒˆã®ã¿ã‚’å‡¦ç†
    for event in events:
        event_start = event['start'].get('dateTime')
        if not event_start:
            continue
            
        event_start_dt = datetime.datetime.fromisoformat(event_start.replace('Z', '+00:00'))
        
        # æŒ‡å®šæœŸé–“å†…ã®ã‚¤ãƒ™ãƒ³ãƒˆã®ã¿ã‚’å‡¦ç†
        if event_start_dt < start_date or event_start_dt > end_date:
            continue
            
        # Check if event title matches the driving log pattern
        if 'è·é›¢' in event.get('summary', ''):
            distance, fuel_efficiency = parse_event_title(event.get('summary', ''))
            
            if distance is not None:
                start_time = event['start'].get('dateTime')
                end_time = event['end'].get('dateTime')
                destination = get_address_from_location(gmaps_client, event.get('location', ''))
                
                # æ‰€è¦æ™‚é–“ã‚’è¨ˆç®—ï¼ˆåˆ†å˜ä½ï¼‰
                duration_minutes = 0
                if start_time and end_time:
                    start_dt = datetime.datetime.fromisoformat(start_time.replace('Z', '+00:00'))
                    end_dt = datetime.datetime.fromisoformat(end_time.replace('Z', '+00:00'))
                    duration = end_dt - start_dt
                    duration_minutes = int(duration.total_seconds() / 60)
                
                # å…ƒã®ä½ç½®æƒ…å ±ã‚’ä¿å­˜ï¼ˆGoogle Mapsãƒªãƒ³ã‚¯ç”¨ï¼‰
                raw_location = event.get('location', '')
                
                # If we have a previous event, use its location as the origin
                origin = "ä¸æ˜"  # Default to unknown
                origin_location = ""  # å…ƒã®ä½ç½®æƒ…å ±ï¼ˆGoogle Mapsãƒªãƒ³ã‚¯ç”¨ï¼‰
                if previous_event:
                    origin = get_address_from_location(gmaps_client, previous_event.get('location', ''))
                    origin_location = previous_event.get('location', '')
                
                logs.append({
                    'start_time': start_time,
                    'end_time': end_time,
                    'origin': origin,
                    'destination': destination,
                    'distance': distance,
                    'fuel_efficiency': fuel_efficiency,
                    'duration_minutes': duration_minutes,  # æ‰€è¦æ™‚é–“ï¼ˆåˆ†ï¼‰ã‚’è¿½åŠ 
                    'origin_location': origin_location,    # å…ƒã®ä½ç½®æƒ…å ±ã‚’è¿½åŠ 
                    'destination_location': raw_location   # å…ƒã®ä½ç½®æƒ…å ±ã‚’è¿½åŠ 
                })
                
                # Update previous event for next iteration
                previous_event = event
    
    return logs

def export_to_csv(logs: List[Dict[str, Any]], file) -> None:
    """Export driving logs to CSV with Shift_JIS encoding."""
    # CSVã«æ‰€è¦æ™‚é–“ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
    fieldnames = ['å‡ºç™ºæ™‚åˆ»', 'åˆ°ç€æ™‚åˆ»','æ‰€è¦æ™‚é–“(åˆ†)', 'å‡ºç™ºåœ°', 'åˆ°ç€åœ°', 'ç§»å‹•è·é›¢', 'ç‡ƒè²»']
    
    # UTF-8ã§ä¸€æ™‚æ–‡å­—åˆ—ãƒãƒƒãƒ•ã‚¡ã«æ›¸ãè¾¼ã¿
    import io
    temp_buffer = io.StringIO()
    writer = csv.DictWriter(temp_buffer, fieldnames=fieldnames)
    writer.writeheader()
    
    for log in logs:
        writer.writerow({
            'å‡ºç™ºæ™‚åˆ»': log['start_time'],
            'åˆ°ç€æ™‚åˆ»': log['end_time'],
            'æ‰€è¦æ™‚é–“(åˆ†)': log['duration_minutes'],
            'å‡ºç™ºåœ°': log['origin'],
            'åˆ°ç€åœ°': log['destination'],
            'ç§»å‹•è·é›¢': log['distance'],
            'ç‡ƒè²»': log['fuel_efficiency']
        })
    
    # UTF-8ã‹ã‚‰Shift_JISã«å¤‰æ›
    utf8_content = temp_buffer.getvalue()
    shift_jis_content = utf8_content.encode('shift_jisx0213', errors='replace')
    
    # ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰ã§æ›¸ãè¾¼ã¿
    if hasattr(file, 'write'):
        # ã™ã§ã«é–‹ã„ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
        if hasattr(file, 'mode') and 'b' in file.mode:
            # ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰ã§é–‹ã‹ã‚Œã¦ã„ã‚‹å ´åˆ
            file.write(shift_jis_content)
        else:
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§é–‹ã‹ã‚Œã¦ã„ã‚‹å ´åˆ
            file.write(shift_jis_content.decode('shift_jisx0213'))
    else:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å ´åˆ
        with open(file, 'wb') as f:
            f.write(shift_jis_content)

if __name__ == '__main__':
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–
    init_cache_db()
    print("ğŸ“ ãƒªãƒãƒ¼ã‚¹ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼šæœ¬ç•ªç’°å¢ƒã§ã¯ç’°å¢ƒå¤‰æ•°ã§ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’åˆ¶å¾¡
    debug_mode = os.environ.get('DEBUG', 'True').lower() == 'true'
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è­¦å‘Š
    if debug_mode and app.secret_key == 'your_secret_key_change_this_in_production':
        print("âš ï¸  è­¦å‘Š: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚æœ¬ç•ªç’°å¢ƒã§ã¯å¿…ãšå¤‰æ›´ã—ã¦ãã ã•ã„ã€‚")
    
    if debug_mode:
        print("ğŸ”§ é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­ - æœ¬ç•ªç’°å¢ƒã§ã¯ DEBUG=False ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    
    app.run(debug=debug_mode, host='0.0.0.0', port=5000)